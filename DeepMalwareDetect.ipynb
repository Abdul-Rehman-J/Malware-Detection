{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepMalwareDetect.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISqfusqLB6uQ"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "***DeepDetectMalware***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFDNbvkIEpaS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "532d057e-6fcd-4789-c021-239efd536329"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SdVzPX2EULb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_selection import SelectKBest,f_classif\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,cohen_kappa_score,f1_score,recall_score,precision_score,accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import LSTM, GRU, Embedding, Dense\n",
        "from keras.activations import sigmoid, softmax, tanh\n",
        "from keras.optimizers import adam, sgd\n",
        "from keras.models import Model, Sequential\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, MultiLabelBinarizer\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70KsvtWBIyh5"
      },
      "source": [
        "# data = pd.read_csv('/content/drive/My Drive/Normalizedataset.csv', sep=',')\n",
        "data = pd.read_csv('/content/drive/My Drive/DynamicLayerDataset.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIyD1FCScbwh"
      },
      "source": [
        "np.unique(data['<Family>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1pQuOiBJUFO"
      },
      "source": [
        "# data=data.drop(['BinaryType','category'], axis=1)\n",
        "# data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HIcAquuUYOW"
      },
      "source": [
        "X=data.iloc[:,:-1] \n",
        "Y=data.iloc[:,-1]\n",
        "cols = X.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxqjD9pWJZdZ"
      },
      "source": [
        "# #for conventaional algotirhms\n",
        "\n",
        "# encoder = LabelEncoder()\n",
        "# encoder.fit(data.iloc[:,-1])\n",
        "# data['family'] = encoder.transform(data.iloc[:,-1])\n",
        "# # print(transformed_label)\n",
        "# # cols = data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baUR-eGyULXm"
      },
      "source": [
        "#for Deep Learning algotirhms\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "Y = np_utils.to_categorical(encoded_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKZjj7H3Jyrp"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X,columns=cols)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmreTuHyp0JM"
      },
      "source": [
        "print (np.unique(Y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmlUqZzG1E-"
      },
      "source": [
        "# #Using Pearson Correlation for feature selection\n",
        "# plt.figure(figsize=(12,10))\n",
        "# cor = data.corr()\n",
        "# sns.heatmap(cor, cmap=plt.cm.Reds)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0wS8QzNI7lz"
      },
      "source": [
        "# #Correlation with output variable\n",
        "# cor_target = abs(cor[\"class\"])\n",
        "# #Selecting highly correlated features\n",
        "# relevant_features = cor_target[cor_target>0.4]\n",
        "# relevant_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adAhv6pDJ1PG"
      },
      "source": [
        "# # feature extraction\n",
        "# test = SelectKBest(score_func=f_classif, k=10)\n",
        "# fit = test.fit(X, Y)\n",
        "# # summarize scores\n",
        "# set_printoptions(precision=3)\n",
        "# print(fit.scores_)\n",
        "# features = fit.transform(X)\n",
        "# # summarize selected features\n",
        "# print(features[0:5,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwjFriK5kt-0"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, random_state=1000)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK9Hm_OuHGHt"
      },
      "source": [
        "np.unique(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqHB3fRmXTC1"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COINn8tLXRox"
      },
      "source": [
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# # Create Decision Tree classifer object\n",
        "# clf = DecisionTreeClassifier()\n",
        "\n",
        "# # Train Decision Tree Classifer\n",
        "# clf = clf.fit(X_train,Y_train)\n",
        "\n",
        "# #Predict the response for test dataset\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# # predictions = tree.predict_proba(X_test)\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# print(confusion_matrix(Y_test, y_pred))\n",
        "# print(classification_report(Y_test, y_pred))\n",
        "\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
        "# print(\"F1-Score:\",metrics.f1_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Recall:\",metrics.recall_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Precision:\",metrics.precision_score(Y_test, y_pred,average='weighted'))\n",
        "# # print (\"Roc Curve\",metrics.roc_auc_score(Y_test, predict_proba[:,1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFUqkvsYiqR"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q56VGmpKYjF9"
      },
      "source": [
        "# clf = GaussianNB()\n",
        "# clf = clf.fit(X_train,Y_train)\n",
        "\n",
        "# #Predict the response for test dataset\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# # predictions = tree.predict_proba(X_test)\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# print(confusion_matrix(Y_test, y_pred))\n",
        "# print(classification_report(Y_test, y_pred))\n",
        "\n",
        "\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
        "# print(\"F1-Score:\",metrics.f1_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Recall:\",metrics.recall_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Precision:\",metrics.precision_score(Y_test, y_pred,average='weighted'))\n",
        "# # print (\"Roc Curve\",metrics.roc_auc_score(Y_test, predict_proba[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb2X3zj3iNc_"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XbBc3YEiM1L"
      },
      "source": [
        "# from sklearn import svm\n",
        "\n",
        "# clf = svm.SVC()\n",
        "# clf.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "# #Predict the response for test dataset\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# # predictions = tree.predict_proba(X_test)\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# print(confusion_matrix(Y_test, y_pred))\n",
        "# print(classification_report(Y_test, y_pred))\n",
        "\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
        "# print(\"F1-Score:\",metrics.f1_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Recall:\",metrics.recall_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Precision:\",metrics.precision_score(Y_test, y_pred,average='weighted'))\n",
        "# # print (\"Roc Curve\",metrics.roc_auc_score(Y_test, predict_proba[:,1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ1CwHOUjBlg"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fBto4b6iMIT"
      },
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "# clf.fit(X_train, Y_train)\n",
        "# MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')\n",
        "\n",
        "# #Predict the response for test dataset\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# # predictions = tree.predict_proba(X_test)\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# print(confusion_matrix(Y_test, y_pred))\n",
        "# print(classification_report(Y_test, y_pred))\n",
        "\n",
        "\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
        "# print(\"F1-Score:\",metrics.f1_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Recall:\",metrics.recall_score(Y_test, y_pred,average='weighted'))\n",
        "# print(\"Precision:\",metrics.precision_score(Y_test, y_pred,average='weighted'))\n",
        "# # print (\"Roc Curve\",metrics.roc_auc_score(Y_test, predict_proba[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq0WyTZPXZWJ"
      },
      "source": [
        "**Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryxLNaKJl6dF"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(130, input_dim=918, activation='relu'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(39, activation='softmax'))\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jZP0rDVmQM3",
        "scrolled": true
      },
      "source": [
        "history=model.fit(x=X_train,y=Y_train,validation_split=0.20,batch_size=6,epochs=50,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwLpKptWAI09"
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'],marker='+')\n",
        "plt.plot(history.history['val_acc'],color='cyan',marker='*')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'],marker='+')\n",
        "plt.plot(history.history['val_loss'],color='cyan',marker='*')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x14VL7vGqhDN"
      },
      "source": [
        "# evaluate the model\n",
        "train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
        "test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "print(\"Train Accuracy is\",train_acc)\n",
        "print(\"Test Accuracy is\",test_acc)\n",
        "\n",
        "val_loss, val_acc = model.evaluate(X_test, Y_test)\n",
        "print(\"Validation Accuracy is\",val_acc)\n",
        "print(\"Validation Loss is\",val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBEtlnGVGcXN"
      },
      "source": [
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(X_test, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(X_test, verbose=0)\n",
        "print(yhat_classes)\n",
        "print(Y_test)\n",
        "# reduce to 1d array\n",
        "# yhat_probs = yhat_probs[:, 0]\n",
        "# yhat_classes = yhat_classes[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5tcF8t3GcDx"
      },
      "source": [
        "import numpy as np\n",
        "Y_test=np.argmax(Y_test, axis=1)\n",
        "Y_test[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC4U1M0B8yqc"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(Y_test, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(Y_test, yhat_classes,average='weighted')\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(Y_test, yhat_classes,average='weighted')\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(Y_test, yhat_classes,average='weighted')\n",
        "print('F1 score: %f' % f1)\n",
        "# kappa\n",
        "kappa = cohen_kappa_score(Y_test, yhat_classes)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(Y_test, yhat_probs.round())\n",
        "print('ROC AUC: %f' % auc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWA1nvw-Gw5l"
      },
      "source": [
        "ns_probs=[0 for _ in range(len(Y_test))]\n",
        "# # keep probabilities for the positive outcome only\n",
        "# lr_probs = yhat_probs[:, 1]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(Y_test, ns_probs)\n",
        "lr_auc = roc_auc_score(Y_test, yhat_probs)\n",
        "\n",
        "# summarize scores\n",
        "print('Abnormal: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Normal: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "# calculate roc curves\n",
        "\n",
        "ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(Y_test, yhat_probs)\n",
        "# plot the roc curve for the model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label=ns_auc)\n",
        "plt.plot(lr_fpr, lr_tpr, marker='*', label=lr_auc)\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bcHXY6LDuwa"
      },
      "source": [
        "# confusion matrix\n",
        "cf_matrix = confusion_matrix(Y_test, yhat_classes)\n",
        "print(cf_matrix)\n",
        "df_cm = pd.DataFrame(cf_matrix, \n",
        "  index = ['adware', 'ransomware', 'scareware', 'smsMalware'],\n",
        "  columns = ['adware', 'ransomware', 'scareware', 'smsMalware'])\n",
        "# sns.heatmap(df_cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ijLLX1K8hyQ"
      },
      "source": [
        "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
        "# sns.heatmap(df_cm/np.sum(df_cm), annot=True, fmt='.2%', cmap='Blues') #for better look divide by 2\n",
        "sns.heatmap(df_cm/np.sum(df_cm)*100, annot=True, vmin=0.0, vmax=100.0, fmt='.2f', cmap=cmap)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5qMxNzDraCc"
      },
      "source": [
        "model.save('adsd.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yERwKRElrjoe"
      },
      "source": [
        "new_model = tf.keras.models.load_model('adsd.model')\n",
        "predictions = new_model.predict(X_test)\n",
        "print(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK7ZTcY5rnbH"
      },
      "source": [
        "print(np.argmax(predictions[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZduO3ajkOuMk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}